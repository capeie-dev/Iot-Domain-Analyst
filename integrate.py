#!/usr/bin/env python3
import numpy as np
import cv2
import pyocr
import pyocr.builders
from PIL import Image
import re
import datetime
from firebase import firebase
from google.cloud import storage
import os
firebase = firebase.FirebaseApplication('https://iot-domain-analyst-156c3-default-rtdb.asia-southeast1.firebasedatabase.app/',None)
os.environ["GOOGLE_APPLICATION_CREDENTIALS"]="/home/capeie/FacemaskDetection/iot-domain-analyst-156c3-firebase-adminsdk-7nqm7-49bacb8840.json"

client = storage.Client()
bucket = client.get_bucket('iot-domain-analyst-156c3.appspot.com')
imageBlob = bucket.blob("/")
# Lists serve as the file
nameList = []   
regNoList = []          
phoneNoList = []       

# Firebase path


#Regex for Registration Number
def extract_reg_number(string):
    pat3 = re.compile(r'[0-2][0-9][B|M][A-Z][A-Z][0-2][0-9][0-9][0-9]')
    re3 = pat3.findall(string)
    re3 = ''.join(re3)
    return re3

#Regex for Name
def extract_names(string):
    pattern = re.compile(r'[A-Z][a-z]+')
    names = pattern.findall(string)
    newname = ' '.join(names)
    return newname

#Regex for Phone Number
def extract_phoneNo(string):
    pat2 = re.compile(r'[6-9][0-9]{9}')
    number = pat2.findall(string)
    number = ''.join(number)
    return number

# Activate Tesseract
tools = pyocr.get_available_tools()
tool = tools[0]
print("Please show your ID card in front of the camera")
# Open Camera
cap = cv2.VideoCapture(0)
while(True):
    #Image Preprocessing
    ret, frame = cap.read()
    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
    ret, threshd = cv2.threshold(gray, 50, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU) 
    
    #OCR in Action
    txt = tool.image_to_string(Image.fromarray(gray), builder=pyocr.builders.TextBuilder())

    RegID = extract_reg_number(txt)
    Name = extract_names(txt)
    PhoneNumber = extract_phoneNo(txt)

    if(RegID != ""):
        regNoList.append(RegID)

    if(Name != ""):
        nameList.append(Name)
    
    if(PhoneNumber != ""):
        phoneNoList.append(PhoneNumber)

    cv2.putText(frame, "Please show your ID card", (150,100),cv2.FONT_HERSHEY_SIMPLEX,0.8,(0,255,255),2)
    cv2.imshow("frame", frame)
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break
    elif RegID != "":
        print(RegID)
        break
cap.release()
cv2.destroyAllWindows()


# -*- coding: utf-8 -*-
"""project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1PvL4MjEppJqGH97djceoPkUJ08iPBiCB
"""
location ='SJT'
import os
import zipfile
import random
import shutil
import tensorflow as tf
from tensorflow.keras.optimizers import RMSprop
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from shutil import copyfile
from os import getcwd
from os import listdir
import cv2
from tensorflow.keras.layers import Conv2D, Input, ZeroPadding2D, BatchNormalization, Activation, MaxPooling2D, Flatten, Dense
from tensorflow.keras.models import Model, load_model
from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint
from sklearn.model_selection import train_test_split
from sklearn.metrics import f1_score
from sklearn.utils import shuffle
import imutils
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.image  as mpimg
from tensorflow import keras
maxposcnt=0

def img_preprocess(img):
  img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)
  img = cv2.resize(img,(150,150))
  img = img/255
  return img

model = keras.models.load_model('facemask.h5')
classifier = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')
cap = cv2.VideoCapture(0)
labels_dict={0:'mask',1:'nomask'}
while(True):
  ret,img = cap.read()
  test = img
  size = 4
  new = img
  mini = cv2.resize(img, (img.shape[1] // size, img.shape[0] // size))

  faces = classifier.detectMultiScale(mini)
  try:
    for f in faces:
      (x, y, w, h) = [v * size for v in f] #Scale the shapesize backup
      #Save just the rectangle faces in SubRecFaces
      face_img = img[y:y+h, x:x+w]
      resized=cv2.resize(face_img,(150,150))
      new = resized
      img = img_preprocess(new)
      img = np.expand_dims(img, axis=0)
      out = model.predict(img)
      out = out[0]
      out = out.tolist()
      maxpos = out.index(max(out))
      print(labels_dict[maxpos])
      if maxpos == 0:
          maxposcnt+=1
          cv2.rectangle(test,(x,y),(x+w,y+h),(0,255,0),2)
          cv2.putText(test, "Welcome back!", (150,100),cv2.FONT_HERSHEY_SIMPLEX,0.8,(0,255,0),2)
      elif maxpos == 1:
        cv2.rectangle(test,(x,y),(x+w,y+h),(0,0,255),2)
        cv2.putText(test, "Please wear a mask!", (150,100),cv2.FONT_HERSHEY_SIMPLEX,0.8,(0,0,255),2)
      if maxposcnt==1:
          result = firebase.patch('/regid',{'ID':RegID})
          cv2.imwrite('person.jpg',resized)
          imagePath = "./person.jpg"
          imageBlob = bucket.blob("{0}.jpg".format(RegID)) 
          imageBlob.upload_from_filename(imagePath)
  except:
    pass

  cv2.imshow('frame',test)
  if cv2.waitKey(1) & 0xFF == ord('q'):
    break

# When everything done, release the capture
cap.release()
cv2.destroyAllWindows()



    
 


